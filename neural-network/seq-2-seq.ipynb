{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Libraries"
      ],
      "metadata": {
        "id": "HYttgZH2TOOb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==2.3.1 torchvision==0.18.1 torchaudio==2.3.1 --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip install torchtext==0.18"
      ],
      "metadata": {
        "id": "3KhB6evqPu_1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbc51ded-e784-4074-86fd-b8d3435f49b5"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Requirement already satisfied: torch==2.3.1 in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision==0.18.1 in /usr/local/lib/python3.10/dist-packages (0.18.1+cu121)\n",
            "Requirement already satisfied: torchaudio==2.3.1 in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1) (3.4.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1) (2.3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.18.1) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.18.1) (10.4.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.1) (12.6.77)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.3.1) (3.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.3.1) (1.3.0)\n",
            "Requirement already satisfied: torchtext==0.18 in /usr/local/lib/python3.10/dist-packages (0.18.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.18) (4.66.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.18) (2.32.3)\n",
            "Requirement already satisfied: torch>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from torchtext==0.18) (2.3.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.18) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext==0.18) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext==0.18) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext==0.18) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext==0.18) (3.4.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext==0.18) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext==0.18) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext==0.18) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext==0.18) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext==0.18) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext==0.18) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext==0.18) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext==0.18) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext==0.18) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext==0.18) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext==0.18) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext==0.18) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext==0.18) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext==0.18) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.3.0->torchtext==0.18) (12.6.77)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.18) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.18) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.18) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.18) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.3.0->torchtext==0.18) (3.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.3.0->torchtext==0.18) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "cW2hDePBPqDD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67ffa2b8-c9fd-4ec5-c34d-1b945c7032bf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('2.3.1+cu121', '3.4.1')"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # Disable tensorflow debugging logs\n",
        "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
        "import keras\n",
        "import torch\n",
        "import re\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import vocab as Vocab\n",
        "from collections import Counter\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import time\n",
        "torch.__version__, keras.__version__\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "wWNTPVk1PqDG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "beb2e396-263d-4a23-f99b-a8e568189a16"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x782360d96190>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "torch.manual_seed(17)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdER_qPKPqDG"
      },
      "source": [
        "# Processing Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "Cx6deG3OPqDH"
      },
      "outputs": [],
      "source": [
        "def process_text(paths):\n",
        "    total_words = 0\n",
        "\n",
        "    for path in paths:\n",
        "        book = open(path, 'rb').read().decode(encoding='utf-8').lower()\n",
        "        words = book.split()\n",
        "        print(f'{path} - Words: {len(words)}')\n",
        "        total_words += len(words)\n",
        "\n",
        "    print(f'Total Words: {total_words}')\n",
        "\n",
        "    # Extrae palabras y signos de puntuación de un texto.\n",
        "    words = re.findall(r'\\b\\w+\\b|[\\.,;!?()\"\\']', book)\n",
        "\n",
        "    # Genera pares de secuencias de palabras y sus subsecuencias para entrenamiento.\n",
        "    maxlen = 32\n",
        "    text_pairs = []\n",
        "    for i in range(0, len(words), maxlen):\n",
        "        inp = words[i:i + maxlen]\n",
        "        out = words[i + maxlen :i + maxlen * 2]\n",
        "        text_pairs.append((' '.join(inp), ' '.join(out)))\n",
        "        for j in range(maxlen - 1):\n",
        "            text_pairs.append((' '.join(inp[j + 1:]), ' '.join(out)))\n",
        "\n",
        "    # Verificando cómo quedó text_pairs\n",
        "    for i in range(5):\n",
        "        print(text_pairs[i])\n",
        "\n",
        "    return text_pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "xCeqtvWJPqDI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5a29912-a396-4b8f-cee8-c3bbca63825e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./01 Harry Potter and the Sorcerers Stone.txt - Words: 78431\n",
            "./02 Harry Potter and the Chamber of Secrets.txt - Words: 86258\n",
            "./03 Harry Potter and the Prisoner of Azkaban.txt - Words: 109563\n",
            "./04 Harry Potter and the Goblet of Fire.txt - Words: 191798\n",
            "./05 Harry Potter and the Order of the Phoenix.txt - Words: 261673\n",
            "Total Words: 727723\n",
            "('the hottest day of the summer so far was drawing to a close and a drowsy silence lay over the large , square houses of privet drive . cars that were usually', 'gleaming stood dusty in their drives and lawns that were once emerald green lay parched and yellowing for the use of hosepipes had been banned due to drought . deprived of their')\n",
            "('hottest day of the summer so far was drawing to a close and a drowsy silence lay over the large , square houses of privet drive . cars that were usually', 'gleaming stood dusty in their drives and lawns that were once emerald green lay parched and yellowing for the use of hosepipes had been banned due to drought . deprived of their')\n",
            "('day of the summer so far was drawing to a close and a drowsy silence lay over the large , square houses of privet drive . cars that were usually', 'gleaming stood dusty in their drives and lawns that were once emerald green lay parched and yellowing for the use of hosepipes had been banned due to drought . deprived of their')\n",
            "('of the summer so far was drawing to a close and a drowsy silence lay over the large , square houses of privet drive . cars that were usually', 'gleaming stood dusty in their drives and lawns that were once emerald green lay parched and yellowing for the use of hosepipes had been banned due to drought . deprived of their')\n",
            "('the summer so far was drawing to a close and a drowsy silence lay over the large , square houses of privet drive . cars that were usually', 'gleaming stood dusty in their drives and lawns that were once emerald green lay parched and yellowing for the use of hosepipes had been banned due to drought . deprived of their')\n"
          ]
        }
      ],
      "source": [
        "paths = ['./01 Harry Potter and the Sorcerers Stone.txt','./02 Harry Potter and the Chamber of Secrets.txt','./03 Harry Potter and the Prisoner of Azkaban.txt',\n",
        "         './04 Harry Potter and the Goblet of Fire.txt', './05 Harry Potter and the Order of the Phoenix.txt']\n",
        "text_pairs = process_text(paths)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lI3f3migPqDI"
      },
      "source": [
        "# Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "QFmhbXoFPqDI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6fa9a18-a280-4fd9-ff19-dee1da8af472"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:1740: UserWarning: [W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n",
            "  warnings.warn(Warnings.W111)\n"
          ]
        }
      ],
      "source": [
        "# !python -m spacy download en_core_web_sm\n",
        "# Crea un tokenizador de spaCy en inglés.\n",
        "eng_tokenizer = get_tokenizer('spacy', language='en_core_web_sm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "F_umNxQJPqDJ"
      },
      "outputs": [],
      "source": [
        "# Se construye un vocabulario a partir de un conjunto de texto, contando las frecuencias de las palabras y filtrando aquellas que no alcanzan un umbral mínimo\n",
        "\n",
        "def build_vocab(text, tokenizers, min_freq=5):\n",
        "    eng_tokenizer = tokenizers\n",
        "    eng_counter = Counter()\n",
        "    for eng_string_prev_, eng_string_post_ in text:\n",
        "        eng_counter.update(eng_tokenizer(eng_string_prev_))\n",
        "        eng_counter.update(eng_tokenizer(eng_string_post_))\n",
        "    eng_vocab = Vocab(eng_counter, min_freq=min_freq, specials=['<unk>', '<pad>', '<bos>', '<eos>'])\n",
        "    return eng_vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "WJLIo_B3PqDJ"
      },
      "outputs": [],
      "source": [
        "eng_vocab = build_vocab(text_pairs, eng_tokenizer, min_freq=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "rIO-Y_svPqDK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64dd3312-5989-4bd7-a3bd-6170d52f7f98"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12198"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "eng_vocab_size = len(eng_vocab)\n",
        "eng_vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "H0zC6jwtPqDK"
      },
      "outputs": [],
      "source": [
        "# Convertir pares de texto en secuencias tensoriales de índices de vocabulario\n",
        "\n",
        "def data_process(text,maxlen):\n",
        "    data = []\n",
        "    for eng_prev, eng_post in text:\n",
        "        eng_prev_tensor_ = torch.tensor([eng_vocab[token] for token in eng_tokenizer(eng_prev)],\n",
        "                                dtype=torch.long)\n",
        "        eng_post_tensor_ = torch.tensor([eng_vocab[token] for token in eng_tokenizer(eng_post)],\n",
        "                                dtype=torch.long)\n",
        "\n",
        "        if eng_prev_tensor_.shape[0] < maxlen + 1:\n",
        "            data.append((eng_prev_tensor_, eng_post_tensor_))\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "lIQW2OmTPqDK"
      },
      "outputs": [],
      "source": [
        "train_data = data_process(text_pairs, maxlen=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "9DXpJ44APqDK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10620187-c600-4531-a31a-25e80b9a8f8a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "331922"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "len(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "N9fSTY63PqDL"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "PAD_IDX = eng_vocab['<pad>']\n",
        "BOS_IDX = eng_vocab['<bos>']\n",
        "EOS_IDX = eng_vocab['<eos>']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "p7m-WhDYPqDL"
      },
      "outputs": [],
      "source": [
        "# Organizar un lote de datos para el entrenamiento, agrega tokens de inicio y fin a las salidas, iguala las longitudes de las secuencias y devuelve las entradas y salidas ajustadas.\n",
        "\n",
        "def generate_batch(data_batch):\n",
        "    x, y = [], []\n",
        "    for (x_item, y_item) in data_batch:\n",
        "        x.append(x_item)\n",
        "        y.append(torch.cat([torch.tensor([BOS_IDX]),\n",
        "                            y_item,\n",
        "                            torch.tensor([EOS_IDX])], dim=0))\n",
        "\n",
        "    x = pad_sequence(x, batch_first=True, padding_value=PAD_IDX)\n",
        "    y = pad_sequence(y, batch_first=True, padding_value=PAD_IDX)\n",
        "    return x, y[:, :-1], y[:, 1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "0AD2ExzgPqDL"
      },
      "outputs": [],
      "source": [
        "# Cargar y preprocesar los datos de entrenamiento en lotes\n",
        "\n",
        "train_loader = DataLoader(train_data,\n",
        "                        batch_size = batch_size,\n",
        "                        shuffle = True,\n",
        "                        collate_fn = generate_batch,\n",
        "                        num_workers = 2,\n",
        "                        pin_memory = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "p_F2Yb67PqDL"
      },
      "outputs": [],
      "source": [
        "enc_batch, dec_batch, target_batch = next(iter(train_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "HXixLSY-PqDL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cb2a08b-aaad-4f3a-9c9f-c3982bf31a1a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([64, 32]), torch.Size([64, 33]), torch.Size([64, 33]))"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "enc_batch.shape, dec_batch.shape, target_batch.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Construction"
      ],
      "metadata": {
        "id": "qK1ePfZtTVAv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emb_dim = 128\n",
        "model_dim = 256"
      ],
      "metadata": {
        "id": "HT1SuETYUXfp"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoder\n",
        "\n",
        "La clase Encoder implementa un modelo de codificación utilizando embeddings y una LSTM para procesar secuencias de texto, transformando entradas de palabras en vectores y produciendo estados ocultos para su uso en otras partes de un sistema de aprendizaje profundo."
      ],
      "metadata": {
        "id": "v4_iHo0xWb6V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim=256, model_dim=512):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_dim)\n",
        "        self.rnn = nn.LSTM(input_size=emb_dim,\n",
        "                        hidden_size=model_dim,\n",
        "                        num_layers=1,\n",
        "                        batch_first=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x, (hidden, cell) = self.rnn(x)\n",
        "        return (hidden, cell)"
      ],
      "metadata": {
        "id": "fBNQ_Xk4UGUf"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Encoder(eng_vocab_size, emb_dim, model_dim)\n",
        "state_batch = encoder(enc_batch)\n",
        "state_batch[0].shape"
      ],
      "metadata": {
        "id": "feqy-AK7UZr7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19be1dfd-6b36-46dc-d1f9-5c684560807a"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 64, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decoder\n",
        "\n",
        "La clase Decoder implementa un modelo de decodificación que utiliza embeddings y una LSTM para generar secuencias, produciendo logits que representan la probabilidad de cada palabra en el vocabulario en base a la entrada y al estado previo del modelo."
      ],
      "metadata": {
        "id": "Me5n7ahTWmBP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim=256, model_dim=512):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_dim)\n",
        "        self.rnn = nn.LSTM(input_size=emb_dim,\n",
        "                        hidden_size=model_dim,\n",
        "                        num_layers=1,\n",
        "                        batch_first=True)\n",
        "        self.fc1 = nn.Linear(model_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x, state):\n",
        "        x = self.embedding(x)\n",
        "        x, (hidden, cell) = self.rnn(x, state)\n",
        "        x = self.fc1(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "zl5oZZHwWVXG"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder = Decoder(eng_vocab_size, emb_dim, model_dim)\n",
        "output_batch = decoder(dec_batch, state_batch)\n",
        "output_batch.shape, target_batch.shape"
      ],
      "metadata": {
        "id": "R-Bhj8mOWXd7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddfe57a8-0660-45c2-a5d3-a2156f2836ec"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([64, 33, 12198]), torch.Size([64, 33]))"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## seq2seq\n",
        "\n",
        "La clase Seq2seq integra un encoder y un decoder en un único modelo, donde el encoder procesa la secuencia de entrada y produce un estado que el decoder utiliza para generar la secuencia de salida."
      ],
      "metadata": {
        "id": "SCedhlklW4EF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super(Seq2seq, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, inp, tar):\n",
        "        state = self.encoder(inp)\n",
        "        x = self.decoder(tar, state)\n",
        "        return x"
      ],
      "metadata": {
        "id": "NRg-gRkYWy74"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq2seq = Seq2seq(encoder, decoder)\n",
        "output_batch = seq2seq(enc_batch, dec_batch)\n",
        "output_batch.shape"
      ],
      "metadata": {
        "id": "nWZv9kxEW3GV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4258ed58-ca45-4afe-f1bf-a6754d68edb4"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 33, 12198])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "_r9LWC4TXiI-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)"
      ],
      "metadata": {
        "id": "7qNPATq5XqdH"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## train\n",
        "\n"
      ],
      "metadata": {
        "id": "16sYrjnMYCSQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    start = time.time()\n",
        "    running_loss = 0.0\n",
        "    model.train()\n",
        "    for inp_enc, inp_dec, tar_dec in train_loader:\n",
        "        tar_dec = tar_dec.reshape(-1)\n",
        "        inp_enc = inp_enc.to(device)\n",
        "        inp_dec = inp_dec.to(device)\n",
        "        tar_dec = tar_dec.to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(inp_enc, inp_dec)\n",
        "        outputs = outputs.view(-1, outputs.size(-1))\n",
        "        loss = loss_fn(outputs, tar_dec)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f'\\nTime for epoch {epoch} is {time.time()-start:.4f} sec Train loss: {running_loss / len(train_loader):.4f}')"
      ],
      "metadata": {
        "id": "-DUFgXVCXvTl"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## translate\n",
        "\n"
      ],
      "metadata": {
        "id": "3U4KMea2YE1D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def translate(model, sentence, device):\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        eng_idx = torch.tensor([eng_vocab[token] for token in eng_tokenizer(sentence)],\n",
        "                                    dtype=torch.long)\n",
        "        eng_idx = eng_idx.reshape([1, -1])\n",
        "\n",
        "        spa_idx = torch.tensor(BOS_IDX, dtype=torch.long)\n",
        "        spa_idx = spa_idx.reshape([1, -1])\n",
        "\n",
        "        while spa_idx[:, -1] != EOS_IDX:\n",
        "            eng_idx = eng_idx.to(device)\n",
        "            spa_idx = spa_idx.to(device)\n",
        "            logits = model(eng_idx, spa_idx)[:, -1, :]\n",
        "            probs = torch.softmax(logits, dim=-1)\n",
        "\n",
        "            _, idx_next = torch.topk(probs, k=1, dim=-1)\n",
        "            spa_idx = torch.cat((spa_idx, idx_next), dim=1)\n",
        "\n",
        "        output = \" \".join([eng_vocab.get_itos()[_] for _ in spa_idx[0]])\n",
        "        output = output.replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")\n",
        "    print(f'Input: {sentence}')\n",
        "    print(f'Output: {output}')"
      ],
      "metadata": {
        "id": "WOReRYXgX1dU"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementation"
      ],
      "metadata": {
        "id": "_m9T3JrTYSIc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "id": "DZV296PbYXGf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f51d8073-65a4-4452-be27-d357d0ef7be2"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "id": "AnX73O7tZ_-o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbd15f79-c123-43be-eb5d-28b5feb36cf5"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq2seq.to(device)\n",
        "optimizer = optim.Adam(seq2seq.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "mkVipJ8PYRKU"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = ['harry and hermione are dancing under the rain, when voldemort and dumbledore are']"
      ],
      "metadata": {
        "id": "ulh9mxtxYfU8"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 50\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    train(seq2seq, device, train_loader, optimizer, epoch)\n",
        "    for s in sentences:\n",
        "        translate(seq2seq, s, device)"
      ],
      "metadata": {
        "id": "eh8bcUcPYgCI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0ec15b4-a602-4c2e-e777-80a6aad1ad09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Time for epoch 0 is 129.3793 sec Train loss: 0.5708\n",
            "Input: harry and hermione are dancing under the rain, when voldemort and dumbledore are\n",
            "Output:  that you had been dreaming about the corridor . she seemed completely forgotten , she \n",
            "\n",
            "Time for epoch 1 is 129.2112 sec Train loss: 0.4703\n",
            "Input: harry and hermione are dancing under the rain, when voldemort and dumbledore are\n",
            "Output:  so that meant , listen to your whereabouts . i don ' t know \n",
            "\n",
            "Time for epoch 2 is 130.1787 sec Train loss: 0.3953\n",
            "Input: harry and hermione are dancing under the rain, when voldemort and dumbledore are\n",
            "Output:  that you had told the examiner about us just slip an excuse to meet \n",
            "\n",
            "Time for epoch 3 is 129.6139 sec Train loss: 0.3389\n",
            "Input: harry and hermione are dancing under the rain, when voldemort and dumbledore are\n",
            "Output:  that you might have been umbridge in professor snape discovered removed the note in his \n",
            "\n",
            "Time for epoch 4 is 129.8480 sec Train loss: 0.2969\n",
            "Input: harry and hermione are dancing under the rain, when voldemort and dumbledore are\n",
            "Output:  you know . voldemort will know why were you going to do ? ' \n",
            "\n",
            "Time for epoch 5 is 131.7097 sec Train loss: 0.2639\n",
            "Input: harry and hermione are dancing under the rain, when voldemort and dumbledore are\n",
            "Output:  you got your own . anyway , arthur weasley and hogwarts ? the most of you \n",
            "\n",
            "Time for epoch 6 is 127.3520 sec Train loss: 0.2381\n",
            "Input: harry and hermione are dancing under the rain, when voldemort and dumbledore are\n",
            "Output:  you got your scar ? ' ' no but thanks , ' said harry \n",
            "\n",
            "Time for epoch 7 is 127.4026 sec Train loss: 0.2157\n",
            "Input: harry and hermione are dancing under the rain, when voldemort and dumbledore are\n",
            "Output:  you got away and give us the time an ' there ' s no \n",
            "\n",
            "Time for epoch 8 is 128.3037 sec Train loss: 0.2000\n",
            "Input: harry and hermione are dancing under the rain, when voldemort and dumbledore are\n",
            "Output:  you got away with these injuries . you ' ve got a lot of help an \n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}